{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import re\n",
    "import traceback\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "\n",
    "from clsearch import ColumnsSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df_case(df, _id, _visit):\n",
    "  neyear=timedelta(days=455)\n",
    "\n",
    "  case_list = pd.read_csv('CaseList.csv', usecols=['CL_CASE_TYPE','CL_PatientID', 'CL_CASE_DATE'],\n",
    "                         parse_dates = ['CL_CASE_DATE'], \n",
    "                         date_parser=lambda x:pd.to_datetime(x,format='%Y%m%d',errors='coerce'), \n",
    "                         encoding = 'unicode_escape')\n",
    "  \n",
    "#先filter(減少後續搜索時間)\n",
    "#first filter time\n",
    "#直接用min_visit_date - 455當作所以case第一時間(才差一個月，只會多抓幾個case)\n",
    "#date after 20200709(用api抓)\n",
    "  yrago = df[_visit].min()-neyear\n",
    "  case_list = case_list[(case_list['CL_CASE_DATE']>=yrago)&(case_list['CL_CASE_DATE']<datetime(2022,7,9))]\n",
    "    \n",
    "#second filter id\n",
    "  case_list = case_list[case_list['CL_PatientID'].isin(pd.unique(df[_id]))]\n",
    "\n",
    "#rename columns before groupby\n",
    "  case_list.rename(columns={'CL_CASE_DATE': 'time', 'CL_CASE_TYPE': 'case'}, inplace = True)\n",
    "    \n",
    "#drop 'time'or'case' is na(後續補上就好)\n",
    "  case_list.dropna(subset = ['time', 'case'], inplace = True)\n",
    "  \n",
    "#groupby\n",
    "  grouped = case_list.groupby('CL_PatientID')\n",
    "  data = {_id: [], 'group': []}\n",
    "  for k in grouped.indices:\n",
    "    data[_id].append(k)\n",
    "    data['group'].append(grouped.get_group(k)[['time','case']])\n",
    "\n",
    "  grouped_df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "#merge by id: df(id, visit), grouped_df(id, get_grouped)\n",
    "\n",
    "  df_case = df.merge(grouped_df, how='left', on=_id, validate='m:1')\n",
    "  df_case.set_index([_id, _visit], inplace=True)\n",
    "  case_dict = {k: [v['group']] for k, v in df_case.to_dict('index').items()}\n",
    "#case_dict: {(id, visit): [df]...}\n",
    "  return yrago, case_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_year=relativedelta(years=1911)\n",
    "\n",
    "#對耀聖方案，有錯者另外拉成newdf\n",
    "#不要動到原始case_dict裡的grouped_df\n",
    "def CasePair(yrago, case_dict):\n",
    "\n",
    "  sixday=timedelta(days=6)\n",
    "\n",
    "#dict for inner_casecompair\n",
    "  compare_dict={'is1408CKD':['p4302c.xls','p1408c.xls'], 'is1409CKD':['p4302c.xls','p1409c.xls'],\n",
    "            'is4302CKD':['p4301c.xls','p1408c.xls'], 'is4301CKD':['p4301c.xls'],\n",
    "            'is1408':['p1408c.xls'], 'is1409':['p1409c.xls'], \n",
    "            'is7001':['p7001c.xls'], 'is7002':['p7002c.xls'], \n",
    "            'not1408':['n1408c.xls'], 'not1409':['n1409c.xls'], \n",
    "            'is1407':['p1407c.xls'],'not1407':['n1407c.xls']}\n",
    "\n",
    "#抓日期區間\n",
    "  _strfmt='\\d{3}.\\d{2}.\\d{2}'\n",
    "    \n",
    "  def _compair(g, _id, pair_dict):\n",
    "    \n",
    "#sort by time\n",
    "    g = g.sort_values(by=['time'])\n",
    "    \n",
    "    def inner_compair(arrlike, _tm, pair_dict, _case=None, oldcase=None):\n",
    "        \n",
    "#每進到inner_compair一次就copy一次，不然一次apply會用到同一個copy，上一列如果有pop，後一列會被影響\n",
    "      pairdict = pair_dict.copy()\n",
    "      nonlocal newdf, g\n",
    "#arrlike[arg]就算改動g也不會變        \n",
    "      if arrlike[_tm] < StDate or arrlike[_tm] > EnDate:\n",
    "        return\n",
    "    \n",
    "#一開始是輸入_case, 進入recursion是輸入oldcase.        \n",
    "#如果_case+, oldcase=None，代表是一開始。oldcase = arrlike['case']，ct_k=arrlike[_case]\n",
    "      if _case:\n",
    "        \n",
    "        oldcase = arrlike[_case]\n",
    "\n",
    "        if oldcase not in pairdict:\n",
    "          return\n",
    "        ct_k = oldcase\n",
    "#如果未輸入_case，代表innercompair recursion，ct_k=next key，oldcase = oldcase(不用再assign)\n",
    "      else:\n",
    "        ct_k = list(pairdict.keys())[0]\n",
    "\n",
    "#if case start with not, compair only after 20220301(以後可以刪)\n",
    "      if re.match('not', ct_k) and arrlike[_tm]<datetime(2022,3,1):\n",
    "        return\n",
    "    \n",
    "#set index(original index) to idx(do not change index during change g)\n",
    "      idx = arrlike.name\n",
    "\n",
    "#pop key\n",
    "      for ct in pairdict.pop(ct_k):\n",
    "        \n",
    "    \n",
    "#都先插入dummies，之後要比對比較簡單\n",
    "#if ct not in g dummies and chartdict[ct] not empty, insert dummies        \n",
    "        if ct not in g.columns:\n",
    "   \n",
    "          df_ct = chartdict[ct][(chartdict[ct]['id']==_id) & (chartdict[ct]['看診日期']>=yrago)]\n",
    "          if not df_ct.empty:\n",
    "\n",
    "#time>=ct(6天內)新merge才有'看診日期'\n",
    "#merge_asof is left-join(need reindex)\n",
    "\n",
    "            g = pd.merge_asof(g, df_ct, left_on=_tm, right_on='看診日期', tolerance=sixday).set_index(g.index)\n",
    "            \n",
    "#update g with看診日期(如果有對到才會update)，沒對到不會動到\n",
    "            g[_tm].update(g['看診日期'])\n",
    "            \n",
    "#if df_ct not not a subset of g, then merge use outer\n",
    "#use oversize to create new index\n",
    "            oversize = len(set(df_ct['看診日期'].dropna())-set(g[_tm]))\n",
    "            if oversize:\n",
    "              \n",
    "#first drop看診日期for overlapping columns(舊看診日期已經update到g['time'],可以刪)\n",
    "              g.drop(columns='看診日期', inplace=True)\n",
    "              newindex = g.index.union(pd.Index([g.index[-1]+i for i in range(1, oversize+1)]))\n",
    "              g = g.merge(df_ct['看診日期'], \n",
    "                          left_on=_tm, right_on='看診日期', \n",
    "                          how='outer').set_index(newindex)\n",
    "              \n",
    "              g[_tm].update(g['看診日期'])\n",
    "              \n",
    "              g.sort_values(by=_tm, inplace=True)\n",
    "#case fillna with err\n",
    "              g[['case']] = g[['case']].fillna('err')\n",
    "              \n",
    "            g.rename(columns={'看診日期': ct}, inplace = True)\n",
    "#刪id cl\n",
    "            g.drop(columns = 'id', inplace = True)\n",
    "#if any ct not found(no g.columns or is None), move to next pair_dict(now key is already popped)\n",
    "       \n",
    "        if ct not in g.columns or pd.isna(g.at[idx, ct]):\n",
    "            \n",
    "#if pairdict未空則進入比對\n",
    "          if pairdict:\n",
    "            inner_compair(arrlike=arrlike, _tm=_tm, pair_dict=pairdict, oldcase=oldcase)\n",
    "#if pairdict為空，代表沒有匹配到, case改成'err'\n",
    "          else:\n",
    "            g.at[idx, 'case'] = 'err'\n",
    "\n",
    "            newdf=pd.concat([newdf, pd.DataFrame(data={'id':[_id],'time':[arrlike[_tm]],\n",
    "                                                       'oldcase':[oldcase],'newcase':['err']})])\n",
    "          break\n",
    "          \n",
    "     \n",
    "#if ct_k is the true case(無論在何層)(means該層 no break), compair to case, if not case, write into newdf\n",
    "      else:\n",
    "        \n",
    "        if ct_k!=oldcase:\n",
    "          g.at[idx, 'case'] = ct_k\n",
    "\n",
    "          newdf=pd.concat([newdf, pd.DataFrame(data={'id':[_id],'time':[arrlike[_tm]],\n",
    "                                                     'oldcase':[oldcase],'newcase':[ct_k]})])\n",
    "#apply一開始就會設定好範圍，後續增加者不會apply\n",
    "    g.apply(inner_compair, _tm='time', pair_dict=pair_dict, _case='case', axis=1)\n",
    "\n",
    "    return g\n",
    "#CasePair start...\n",
    "#open newdf\n",
    "  newdf = pd.DataFrame(columns = ['id','time','oldcase','newcase']) \n",
    "\n",
    "#先把chartfolder裡檔案都打開，add to chartdict\n",
    "  chartdict={}\n",
    "\n",
    "#檔名通通轉小寫(連igt結案一起讀)\n",
    "  for _f in listdir('casefolder'):\n",
    "\n",
    "    chartdict[_f.lower()]=pd.read_excel(join('casefolder', _f))\n",
    "\n",
    "  StDate, EnDate=tuple(re.findall(_strfmt, chartdict['p1407c.xls'].columns[0]))\n",
    "#抓StDate, EnDate\n",
    "  StDate, EnDate = parse(StDate)+ad_year, parse(EnDate)+ad_year\n",
    "    \n",
    "#抓看診日期和身分證字號row and cl index\n",
    "  rw, cl_list=ColumnsSearch(chartdict['p1407c.xls'], ['身份證字號','看診日期'])\n",
    "    \n",
    "#get all id\n",
    "  ids, _ = zip(*case_dict.keys())\n",
    "    \n",
    "#crop the chartdict, reset column names(***index not reset) and date\n",
    "  for d in chartdict:\n",
    "    chartdict[d] = chartdict[d].iloc[rw:, cl_list]\n",
    "    chartdict[d].columns = ['id','看診日期']\n",
    "    chartdict[d].dropna(inplace = True)\n",
    "    chartdict[d].drop(chartdict[d].index[0], inplace = True)\n",
    "    chartdict[d]['看診日期'] = chartdict[d]['看診日期'].apply(lambda x: parse(x) + ad_year)\n",
    "#(use grouped id to filter chartdict[d],減少後續搜索時間)\n",
    "    chartdict[d] = chartdict[d][chartdict[d]['id'].isin(ids)]\n",
    "\n",
    "#k[0]=id, k[1]=visit, v[group]=g=>change to {(id, visit):[grouped_df]}\n",
    "  case_dict = {k: [v[0].pipe(_compair, _id=k[0], pair_dict=compare_dict) if isinstance(v[0], pd.DataFrame)\n",
    "                   else v[0]] for k, v in case_dict.items()}\n",
    "\n",
    "#check if igt not missing and try change to int 1 if not\n",
    "  check_igt = lambda arrlike, t_x, igt_nearest: 1 if arrlike[t_x]-igt_nearest<=sixday else pd.NA\n",
    "    \n",
    "#抓igt, ckd結案, dm結案時間    \n",
    "  for k,_g in case_dict.items():\n",
    "\n",
    "    if isinstance(_g[0], pd.DataFrame):\n",
    "#抓igt max, create igt cl\n",
    "      igt_nearest = chartdict['igt.xls'].loc[chartdict['igt.xls']['id']==k[0], '看診日期'].max()\n",
    "#不見得比較快，但比較乾淨('time'有誤差未改，但因是igt方案應該沒差)\n",
    "      _g[0]['igt'] = _g[0].apply(check_igt, axis=1, t_x='time', igt_nearest=igt_nearest)\n",
    "    \n",
    "#[]append ckd結案\n",
    "      _g.append(chartdict['ckd結案.xls'].loc[chartdict['ckd結案.xls']['id']==k[0], '看診日期'].max())\n",
    "#[]append dm結案    \n",
    "      _g.append(chartdict['dm結案.xls'].loc[chartdict['dm結案.xls']['id']==k[0], '看診日期'].max())\n",
    "    \n",
    "  newdf.to_csv('casepair.csv', index=False) \n",
    "\n",
    "  return case_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
